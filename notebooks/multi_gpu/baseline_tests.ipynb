{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, jaxfluids uses a classical approach of domain decomposition and ghostcells. I hoped that based on the computations follows data principle, sharding and fusion of operations, JAX could do better without manually handling this - but I might well be wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4\" \n",
    "\n",
    "\n",
    "# os.environ[\"JAX_ENABLE_PGLE\"] = \"true\"\n",
    "# os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_enable_latency_hiding_scheduler=true\"\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax.sharding import PartitionSpec as P, NamedSharding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Difference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=['axis'])\n",
    "def finite_difference(array, axis):\n",
    "    return (jax.lax.slice_in_dim(array, 1, -1, axis = axis) - jax.lax.slice_in_dim(array, 0, -2, axis = axis))\n",
    "\n",
    "@partial(jax.jit, static_argnames=['indices', 'axis', 'zero_pad'])\n",
    "def _stencil_add(\n",
    "        input_array: jnp.ndarray,\n",
    "        indices,\n",
    "        factors,\n",
    "        axis: int,\n",
    "        zero_pad: bool = True\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Combines elements of an array additively\n",
    "        output_i <- sum_j factors_j * input_array_{i + indices_j}\n",
    "\n",
    "    By default, the output is zero-padded to the same shape as \n",
    "    the input array (as we handle boundaries via ghost cells in \n",
    "    the overall simulation code). This behavior can be disabled,\n",
    "    then the output will have a different shape along the specified\n",
    "    axis.\n",
    "\n",
    "    Args:\n",
    "        input_array: The array to operate on.\n",
    "        indices: output_i <- sum_j factors_j * input_array_{i + indices_j}\n",
    "        factors: output_i <- sum_j factors_j * input_array_{i + indices_j}\n",
    "        axis: The axis along which to operate.\n",
    "        zero_pad: Whether to zero-pad the output to have the same shape as the input.\n",
    "        \n",
    "    Returns:\n",
    "        output_i <- sum_j factors_j * input_array_{i + indices_j}\n",
    "    \"\"\"\n",
    "\n",
    "    num_cells = input_array.shape[axis]\n",
    "\n",
    "    first_write_index = -min(0, min(indices))\n",
    "    last_write_index = num_cells - max(0, max(indices))\n",
    "\n",
    "    # for the first write index, the elements considered are\n",
    "    first_handled_indices = tuple(first_write_index + index for index in indices)\n",
    "\n",
    "    # for the last write index, the elements considered are\n",
    "    last_handled_indices = tuple(last_write_index + index for index in indices)\n",
    "\n",
    "    output = (\n",
    "        sum(\n",
    "            factor * jax.lax.slice_in_dim(\n",
    "                input_array,\n",
    "                first_handled_index,\n",
    "                last_handled_index,\n",
    "                axis = axis\n",
    "            )\n",
    "            for factor, first_handled_index, last_handled_index in zip(\n",
    "                factors, first_handled_indices, last_handled_indices\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if zero_pad:\n",
    "        result = jnp.zeros_like(input_array)\n",
    "        selection = (\n",
    "            (slice(None),) * axis +\n",
    "            (slice(first_write_index, last_write_index),) +\n",
    "            (slice(None),)*(input_array.ndim - axis - 1)\n",
    "        )\n",
    "        result = result.at[selection].set(output)\n",
    "        return result\n",
    "    else:\n",
    "        return output\n",
    "\n",
    "@partial(jax.jit)\n",
    "def dummy_fluid_code(array):\n",
    "    # \"time steps\"\n",
    "    for _ in range(10):\n",
    "        # \"axes\"\n",
    "        for axis in range(1, array.ndim):\n",
    "            array += 0.001 * _stencil_add(array, (1, -1), (1.0, -1.0), axis = axis)\n",
    "\n",
    "        # some non-linear computation\n",
    "        # array = jnp.sin(array)\n",
    "        \n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsharded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_per_dim = 470\n",
    "unsharded_array = jax.random.normal(jax.random.key(0), (5, size_per_dim, size_per_dim, size_per_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jnp.sin(unsharded_array)\n",
    "# %timeit -n 10 -r 10 jnp.sin(unsharded_array).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finite_difference(unsharded_array, 1)\n",
    "# %timeit  -n 10 -r 10 finite_difference(unsharded_array, 1).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.3 ms ± 7.74 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "dummy_fluid_code(unsharded_array)\n",
    "%timeit -n 5 -r 5 dummy_fluid_code(unsharded_array).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharded array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = jax.make_mesh((1, 2, 2, 1), ('vars', 'x', 'y', 'z'))\n",
    "sharding = NamedSharding(mesh, P('vars', 'x', 'y', 'z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">   GPU 0    </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">   GPU 1    </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">            </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">            </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">   GPU 2    </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">   GPU 3    </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">            </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">            </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">            </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">            </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m   \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mGPU 0\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m    \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m   \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mGPU 1\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m    \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m            \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m            \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m   \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74mGPU 2\u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m    \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m   \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107mGPU 3\u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m    \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m            \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m            \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m            \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;173;73;74m            \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sharded_array = jax.device_put(unsharded_array, sharding)\n",
    "jax.debug.visualize_array_sharding(sharded_array[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15 ms ± 58.5 μs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "jnp.sin(sharded_array)\n",
    "%timeit -n 10 -r 10 jnp.sin(sharded_array).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.72 ms ± 300 μs per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "finite_difference(sharded_array, 1)\n",
    "%timeit -n 10 -r 10 finite_difference(sharded_array, 1).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.9 ms ± 9.32 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "dummy_fluid_code(sharded_array)\n",
    "%timeit -n 5 -r 5 dummy_fluid_code(sharded_array).block_until_ready()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1uids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
